# Module 09 â€” PERFORMANCE

> **Objectif** : Optimiser l'app pour qu'elle vole. Comprendre les mÃ©triques et les leviers.

> **ğŸ”¬ Clinical Engine** = Performance non critique (50 users), optimisation basique | **ğŸ“± MyMonka** = Performance critique (100K users), CDN, caching Redis, load testing obligatoire

---

## ğŸ¯ PARETO 80/20

> **Les 20% qui couvrent 80% du sujet :**
>
> 1. **Core Web Vitals** (Â§9.1) â€” Les 3 mÃ©triques que Google mesure
> 2. **Lazy loading & code splitting** (Â§9.2) â€” Les gains les plus simples Ã  obtenir
> 3. **N+1 queries** (Â§9.3) â€” Le piÃ¨ge classique cÃ´tÃ© backend

---

## 9.1 â€” Core Web Vitals

Les 3 mÃ©triques de Google pour mesurer l'expÃ©rience utilisateur :

| MÃ©trique | Nom complet | Mesure quoi | Seuil "bon" |
|----------|------------|-------------|-------------|
| **LCP** | Largest Contentful Paint | Temps pour afficher le plus gros Ã©lÃ©ment visible | < 2.5s |
| **INP** | Interaction to Next Paint | RÃ©activitÃ© aux clics/taps (remplace FID) | < 200ms |
| **CLS** | Cumulative Layout Shift | Est-ce que la page "saute" visuellement | < 0.1 |

### Comment les mesurer

- **Lighthouse** (Chrome DevTools â†’ Audit) â†’ Score sur 100
- **PageSpeed Insights** (web.dev/measure) â†’ DonnÃ©es rÃ©elles
- **Vercel Analytics** â†’ Monitoring continu des Web Vitals

### Optimiser le LCP

| ProblÃ¨me | Solution |
|---------|---------|
| Images lourdes | Formats modernes (WebP, AVIF), lazy loading |
| JS trop lourd | Code splitting, tree-shaking |
| Serveur lent | CDN, caching |
| CSS bloquant | Critical CSS inline |

---

## 9.2 â€” Frontend Optimization

### Code Splitting

Au lieu de charger tout le JavaScript d'un coup, on le dÃ©coupe en morceaux chargÃ©s Ã  la demande :

```tsx
// Sans code splitting â€” tout est chargÃ© au dÃ©marrage
import Simulator from './pages/Simulator';
import Admin from './pages/Admin';
import Reports from './pages/Reports';

// Avec code splitting â€” chaque page est chargÃ©e quand on y accÃ¨de
const Simulator = lazy(() => import('./pages/Simulator'));
const Admin = lazy(() => import('./pages/Admin'));
const Reports = lazy(() => import('./pages/Reports'));
```

**Impact** : Si un utilisateur ne visite jamais la page Admin, il ne tÃ©lÃ©charge jamais son code.

### Memoization (React.memo, useMemo, useCallback)

Ã‰viter de recalculer / re-render ce qui n'a pas changÃ© :

```tsx
// Sans memo â€” le composant re-render Ã  chaque render du parent
function PatientCard({ patient }) { ... }

// Avec memo â€” ne re-render que si patient change
const PatientCard = React.memo(function PatientCard({ patient }) { ... });
```

**useMemo** : Mettre en cache un rÃ©sultat de calcul lourd
```tsx
const sortedPatients = useMemo(
  () => patients.sort((a, b) => b.score - a.score),
  [patients] // Recalculer seulement si patients change
);
```

### RÃ¨gle d'or
> Ne pas optimiser prÃ©maturÃ©ment. Mesurer d'abord (Lighthouse), optimiser ensuite. L'ennemi c'est le **premature optimization** â€” Donald Knuth.

---

## 9.3 â€” Backend Optimization

### Le problÃ¨me N+1

Le piÃ¨ge de performance le plus courant :

```
âŒ N+1 requÃªtes (mauvais)
1 requÃªte : "Donne-moi tous les patients" â†’ 100 patients
100 requÃªtes : "Donne-moi les scores du patient 1", "...patient 2", ... "...patient 100"
Total : 101 requÃªtes ğŸ’€

âœ… 2 requÃªtes (bon)
1 requÃªte : "Donne-moi tous les patients"
1 requÃªte : "Donne-moi tous les scores de ces 100 patients" (avec un IN clause)
Total : 2 requÃªtes âœ…
```

Avec **Supabase**, on rÃ©sout Ã§a avec les **relations dans le select** :
```typescript
const { data } = await supabase
  .from('patients')
  .select('*, scores(*)'); // Joint automatiquement en une seule requÃªte
```

### Connection Pooling

PostgreSQL a un nombre limitÃ© de connexions simultanÃ©es. Si chaque requÃªte ouvre une nouvelle connexion â†’ saturation.

**Connection Pool** : Un ensemble de connexions prÃ©-ouvertes et rÃ©utilisÃ©es. Supabase utilise **PgBouncer** pour Ã§a.

### Caching

| Niveau | Quoi | DurÃ©e | Outil |
|--------|------|-------|-------|
| **Browser** | Fichiers statiques (JS, CSS, images) | Jours/semaines | Headers Cache-Control |
| **CDN** | Pages / assets | Minutes/heures | Vercel CDN |
| **API** | RÃ©ponses de requÃªtes | Secondes/minutes | stale-while-revalidate |
| **DB** | RÃ©sultats de requÃªtes frÃ©quentes | Variable | Materialized views |

---

## 9.4 â€” Bundle Size

### Pourquoi Ã§a compte

Plus le bundle est gros, plus le temps de chargement initial est long (surtout sur mobile/3G).

### Comment rÃ©duire

| Technique | Gain |
|-----------|------|
| **Tree-shaking** | Supprime le code mort automatiquement (Vite fait Ã§a) |
| **Dynamic imports** | Charge les modules Ã  la demande |
| **Analyse du bundle** | `npx vite-bundle-visualizer` â†’ voir ce qui prend de la place |
| **Alternatives lÃ©gÃ¨res** | Remplacer les grosses librairies (moment.js â†’ date-fns) |

---

## 9.5 â€” ScalabilitÃ©

### Vertical vs Horizontal

| Type | MÃ©thode | Limite | CoÃ»t |
|------|---------|--------|------|
| **Vertical** | Machine plus puissante | Plafond physique | LinÃ©aire |
| **Horizontal** | Plus de machines | Quasi illimitÃ© | Plus complexe |

### L'architecture Monka scale nativement

```
Front (Vercel CDN) â†’ Scale infini (fichiers statiques distribuÃ©s)
API (Supabase)     â†’ Scale vertical (upgrade plan) + read replicas
DB (PostgreSQL)    â†’ Scale vertical + partitioning si nÃ©cessaire
Edge Functions     â†’ Scale horizontal (serverless, auto-scale)
```

> ğŸ“Œ **En contexte**
> - ğŸ”¬ **Clinical Engine** : Aucun enjeu de scalabilitÃ©. 50 users, on ne touche mÃªme pas les limites du free tier Supabase.
> - ğŸ“± **MyMonka** : ScalabilitÃ© = enjeu #1. 100K aidants simultanÃ©s nÃ©cessite : PgBouncer (connection pooling), read replicas, cache Redis pour les rÃ©fÃ©rentiels, CDN avec invalidation fine, horizontal scaling des Edge Functions, et potentiellement du sharding DB Ã  terme.

---

## 9.6 â€” Profiling

### Les outils

| Outil | Mesure quoi |
|-------|------------|
| **Chrome DevTools â†’ Performance** | Temps de chargement, rendering, scripting |
| **React DevTools â†’ Profiler** | Re-renders inutiles, composants lents |
| **Lighthouse** | Score de performance global |
| **Supabase Dashboard** | RequÃªtes SQL lentes |
| **`EXPLAIN ANALYZE`** | Plan d'exÃ©cution d'une requÃªte SQL |

### Le workflow d'optimisation

```
1. Mesurer â†’ Lighthouse / DevTools / Supabase Dashboard
2. Identifier â†’ Quel est le bottleneck ? (JS? RÃ©seau? DB?)
3. Optimiser â†’ Appliquer la technique adaptÃ©e
4. Mesurer Ã  nouveau â†’ VÃ©rifier l'amÃ©lioration
5. Ne pas toucher au reste â†’ Si c'est pas cassÃ©, ne le rÃ©pare pas
```

---

> ğŸ’¡ **Takeaway** : La performance, c'est de la data. On mesure, on identifie le goulot d'Ã©tranglement, on optimise CE point, et on re-mesure. Pas d'optimisation au feeling.
