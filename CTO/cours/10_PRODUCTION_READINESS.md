# Module 10 â€” PRODUCTION READINESS

> **Objectif** : Savoir oÃ¹ on en est et ce qui manque.
> C'est LE sujet que le CTO va creuser en premier.

> **ğŸ”¬ Clinical Engine** = POC rÃ©ussi, prod-readiness non requise (outil interne de validation) | **ğŸ“± MyMonka** = Les 12 critÃ¨res sont obligatoires AVANT la mise en production

---

## ğŸ¯ PARETO 80/20

> **Les 20% qui couvrent 80% du sujet :**
>
> 1. **La checklist des 12 critÃ¨res prod-ready** (Â§10.1) â€” Connais-la par cÅ“ur
> 2. **Error handling** (Â§10.2) â€” L'app ne doit JAMAIS crasher silencieusement
> 3. **Monitoring** (Â§10.3) â€” Tu dois savoir quand l'app plante, AVANT l'utilisateur
> 4. **Secrets management** (Â§10.4) â€” ZÃ©ro secret dans le code, point final
>
> Si tu maÃ®trises ces 4 chapitres, tu peux tenir 80% d'une conversation prod-readiness.

---

## 10.1 â€” Qu'est-ce qu'une app "Production-Ready" ?

### Le concept
Un prototype qui "fonctionne" â‰  une application de production. La diffÃ©rence, c'est tout ce qui se passe **quand Ã§a ne fonctionne PAS**.

Un prototype, tu le montres dans une dÃ©mo. Une app de prod, elle tourne **24/7, sans toi, avec de vrais utilisateurs qui font des trucs imprÃ©vus**.

### La checklist des 12 critÃ¨res

| # | CritÃ¨re | Prototype | Production | CriticitÃ© |
|---|---------|-----------|------------|-----------|
| 1 | **Tests automatisÃ©s** | Manuels | Unit + Integration + E2E | ğŸ”´ Critique |
| 2 | **Error handling** | `console.log(error)` | Error boundaries + logging structurÃ© | ğŸ”´ Critique |
| 3 | **Monitoring** | Tu regardes la console | Sentry + alertes automatiques | ğŸ”´ Critique |
| 4 | **Secrets management** | `.env` en local | Vault / Secrets manager | ğŸ”´ Critique |
| 5 | **Backup** | Aucun | Automatique + testÃ© | ğŸ”´ Critique |
| 6 | **Auth & Security** | Login basique | MFA, rate limiting, audit log | ğŸŸ¡ Important |
| 7 | **Performance** | "Ã‡a charge vite chez moi" | Profiling, CDN, caching | ğŸŸ¡ Important |
| 8 | **Documentation** | README basique | ADR, runbooks, API docs | ğŸŸ¡ Important |
| 9 | **CI/CD** | Deploy manuel ou automatique simple | Pipeline avec quality gates | ğŸŸ¡ Important |
| 10 | **Environnements** | Dev = Prod | Dev / Staging / Prod isolÃ©s | ğŸŸ¡ Important |
| 11 | **ScalabilitÃ©** | "Ã‡a marche pour 10 users" | Load tested pour la cible | ğŸŸ¢ Nice-to-have (dÃ©but) |
| 12 | **Compliance** | IgnorÃ©e | RGPD, HDS, audits | ğŸ”´ Critique (santÃ©) |

### OÃ¹ en est Monka ?
Soyons honnÃªtes (le CTO apprÃ©ciera la transparence) :

| CritÃ¨re | Statut Monka | Commentaire |
|---------|-------------|-------------|
| Tests | âš ï¸ Partiellement | Integrity checks sur le Kernel, pas de tests automatisÃ©s classiques |
| Error handling | âš ï¸ Basique | Pas d'Error Boundaries systÃ©matiques |
| Monitoring | âŒ Absent | Pas de Sentry ni de logging structurÃ© |
| Secrets | âœ… OK | `.env` + Vercel secrets, rien dans le code |
| Backup | âš ï¸ Supabase auto | Backup Supabase activÃ©, mais pas de stratÃ©gie DR formelle |
| Auth | âœ… OK | Supabase Auth avec RLS |
| Performance | âš ï¸ Non profilÃ© | Pas de Lighthouse audit formel |
| Documentation | âœ… Riche | Kernel documentÃ©, certifications, audits |
| CI/CD | âœ… OK | Vercel auto-deploy |
| Environnements | âš ï¸ Partiel | Dev/Prod sÃ©parÃ©s, pas de staging formel |
| ScalabilitÃ© | âš ï¸ Non testÃ© | Architecture OK, mais pas de load test |
| Compliance | âš ï¸ Conscient | RLS OK, HDS identifiÃ© comme nÃ©cessaire, pas encore implÃ©mentÃ© |

---

## 10.2 â€” Error Handling (Gestion des erreurs)

### Le concept
Imagine une autoroute sans glissiÃ¨re de sÃ©curitÃ©. Quand tout va bien, personne ne les remarque. Quand quelque chose va mal, elles sauvent des vies. L'error handling, c'est les **glissiÃ¨res de sÃ©curitÃ© de ton code**.

### Les 3 niveaux

#### Niveau 1 : Try/Catch (JavaScript natif)

Le mÃ©canisme de base pour "entourer" du code risquÃ© :

```typescript
// âŒ MAUVAIS â€” L'erreur est avalÃ©e silencieusement
try {
  const data = await fetchPatientData(id);
} catch (e) {
  // Rien... L'utilisateur voit un Ã©cran vide.
}

// âœ… BON â€” L'erreur est gÃ©rÃ©e proprement
try {
  const data = await fetchPatientData(id);
} catch (error) {
  // 1. Logger pour les devs
  logger.error('Erreur chargement patient', { patientId: id, error });
  
  // 2. Informer l'utilisateur
  showNotification('Impossible de charger les donnÃ©es. RÃ©essayez.');
  
  // 3. Reporter au monitoring
  Sentry.captureException(error);
}
```

**RÃ¨gle** : Chaque `catch` doit faire 3 choses â€” **logger**, **informer**, **reporter**.

#### Niveau 2 : Error Boundaries (React spÃ©cifique)

Un **Error Boundary** est un composant React spÃ©cial qui "attrape" les erreurs de ses composants enfants. Sans Ã§a, une erreur dans un composant = toute l'app crashe (Ã©cran blanc).

```tsx
// L'Error Boundary entoure les composants Ã  risque
<ErrorBoundary fallback={<p>Quelque chose s'est mal passÃ©. Rechargez la page.</p>}>
  <ClinicalScoring /> {/* Si ce composant crashe... */}
</ErrorBoundary>
{/* ...le reste de l'app continue de fonctionner */}
<NavigationBar />
```

**Analogie** : C'est comme un fusible Ã©lectrique. Si un appareil court-circuite, le fusible saute pour CE circuit, mais le reste de la maison continue d'avoir du courant.

#### Niveau 3 : Graceful Degradation

L'idÃ©e : si un service est down, l'app continue de fonctionner en mode dÃ©gradÃ© au lieu de crasher totalement.

Exemples :
- La DB est lente â†’ afficher les donnÃ©es en cache
- Le service de scoring est down â†’ afficher "RÃ©sultats temporairement indisponibles" au lieu d'un Ã©cran blanc
- L'API externe (IDEC) ne rÃ©pond pas â†’ fonctionner en mode offline avec les derniÃ¨res donnÃ©es connues

---

## 10.3 â€” Logging & Monitoring

### Le concept
**Logging** = Ã©crire un journal de tout ce qui se passe dans l'app.
**Monitoring** = surveiller ce journal en temps rÃ©el et alerter quand quelque chose va mal.

Sans monitoring, tu dÃ©couvres les bugs quand un utilisateur t'appelle. Avec monitoring, tu le sais avant lui.

### Les niveaux de log

```
DEBUG   â†’ DÃ©tails techniques (pour les devs en dÃ©veloppement)
INFO    â†’ Ã‰vÃ©nements normaux (utilisateur connectÃ©, scoring calculÃ©)
WARN    â†’ Situations anormales mais pas critiques (temps de rÃ©ponse lent)
ERROR   â†’ Quelque chose a plantÃ© (requÃªte Ã©chouÃ©e, calcul impossible)
FATAL   â†’ L'app est cassÃ©e (base de donnÃ©es inaccessible)
```

### Structured Logging

**âŒ Log non structurÃ©** (inutile en prod) :
```
"Erreur lors du calcul du score pour le patient"
```

**âœ… Log structurÃ©** (exploitable) :
```json
{
  "level": "ERROR",
  "message": "Score calculation failed",
  "timestamp": "2026-02-27T15:30:00Z",
  "patientId": "abc-123",
  "module": "V3_scoring",
  "error": "Division by zero in vulnerability index",
  "userId": "user-456",
  "requestId": "req-789"
}
```

Avec un log structurÃ©, tu peux **filtrer**, **chercher**, et **alerter** automatiquement. "Montre-moi toutes les erreurs du module V3 dans les derniÃ¨res 24h" â†’ 2 secondes.

### Outils de monitoring

| Outil | Usage | CoÃ»t |
|-------|-------|------|
| **Sentry** | Capture automatique des erreurs + stack traces | Gratuit pour petits volumes |
| **Datadog** | Monitoring complet (logs, metrics, traces) | Payant, puissant |
| **Vercel Analytics** | Performance web (Core Web Vitals) | Inclus dans Vercel |
| **Supabase Dashboard** | MÃ©triques DB (requÃªtes lentes, connections) | Inclus dans Supabase |

### Correlation ID

Un concept pro : Ã  chaque requÃªte d'un utilisateur, on gÃ©nÃ¨re un ID unique (`requestId`). Cet ID est propagÃ© dans tous les logs liÃ©s Ã  cette requÃªte. Si un utilisateur signale "Ã§a a plantÃ©", il te donne le `requestId` â†’ tu retrouves toute la chaÃ®ne d'Ã©vÃ©nements en 10 secondes.

---

## 10.4 â€” Environment Config & Secrets Management

### Le concept
Les **secrets** (clÃ©s API, mots de passe DB, tokens) ne doivent JAMAIS Ãªtre dans le code source. Si ton repo Git est compromis, tes secrets sont exposÃ©s.

### La rÃ¨gle d'or

```
CODE SOURCE = PUBLIC (mÃªme si repo privÃ©, traite-le comme potentiellement public)
SECRETS = DANS L'ENVIRONNEMENT (variables d'env, secrets manager)
```

### HiÃ©rarchie des mÃ©thodes (de basique Ã  pro)

| Niveau | MÃ©thode | Quand l'utiliser |
|--------|---------|-----------------|
| 1 | Fichier `.env` + `.gitignore` | DÃ©veloppement local |
| 2 | Variables d'env du provider (Vercel, GitHub) | CI/CD et production |
| 3 | Secrets Manager (AWS SSM, Vault) | Entreprise, compliance forte |

### Le piÃ¨ge du front-end

**Attention** : En React, toute variable d'environnement prÃ©fixÃ©e `VITE_` est **incluse dans le bundle** et visible par n'importe qui dans le navigateur (via les DevTools).

```
VITE_SUPABASE_URL=xxx        â† VISIBLE dans le navigateur (OK, c'est prÃ©vu)
VITE_SUPABASE_ANON_KEY=xxx   â† VISIBLE dans le navigateur (OK, le RLS protÃ¨ge)
SUPABASE_SERVICE_ROLE_KEY=xxx â† INVISIBLE, pas prÃ©fixÃ© VITE_ (CRITIQUE, jamais cÃ´tÃ© client)
```

La **anon key** Supabase est **publique par design**. Ce n'est PAS un secret. Le RLS garantit que mÃªme avec cette clÃ©, un utilisateur ne voit que ses donnÃ©es.

La **service_role key** donne un accÃ¨s admin total Ã  la DB. Elle ne doit exister QUE cÃ´tÃ© serveur (Edge Functions, scripts d'admin).

### Validation de config

Au dÃ©marrage de l'app, **valider** que toutes les variables nÃ©cessaires sont prÃ©sentes :
```typescript
const requiredEnvVars = ['VITE_SUPABASE_URL', 'VITE_SUPABASE_ANON_KEY'];

for (const envVar of requiredEnvVars) {
  if (!import.meta.env[envVar]) {
    throw new Error(`Variable d'environnement manquante : ${envVar}`);
  }
}
```

Un crash au dÃ©marrage avec un message clair > un bug mystÃ©rieux 3 heures plus tard.

---

## 10.5 â€” Health Checks & Readiness Probes

### Le concept
Comment savoir si ton application est **vivante** et **prÃªte** Ã  servir des requÃªtes ?

### Health Check Endpoint

Un endpoint simple qui rÃ©pond "je suis en vie" :

```typescript
// GET /api/health
{
  "status": "healthy",
  "version": "1.2.3",
  "uptime": "72h",
  "database": "connected",
  "timestamp": "2026-02-27T15:30:00Z"
}
```

**Liveness** = "L'app tourne ?" â†’ Si non, redÃ©marrer.
**Readiness** = "L'app est prÃªte Ã  servir ?" â†’ Si non, ne pas envoyer de trafic.

DiffÃ©rence : l'app peut Ãªtre vivante (le process tourne) mais pas ready (la DB n'est pas encore connectÃ©e). Un load balancer n'envoie du trafic qu'aux instances ready.

---

## 10.6 â€” Rollback Strategy

### Le concept
Question fondamentale : **si le dÃ©ploiement casse tout, comment tu reviens en arriÃ¨re en 30 secondes ?**

### Les 3 stratÃ©gies

#### 1. Rollback simple (Vercel)
Vercel garde un historique de chaque dÃ©ploiement. En un clic, tu redÃ©ploies la version prÃ©cÃ©dente. Simple, efficace, suffisant pour commencer.

#### 2. Blue-Green Deployment
```
                    â”Œâ”€â”€â”€ Blue (v1.0 â€” ACTUEL) â—„â”€â”€ trafic utilisateurs
Load Balancer â”€â”€â”€â”€â”€â”€â”¤
                    â””â”€â”€â”€ Green (v1.1 â€” NOUVEAU, en test)
```
- Tu dÃ©ploies la v1.1 sur Green
- Tu testes sur Green (URL privÃ©e)
- Tu bascules le trafic de Blue vers Green
- Si Ã§a pÃ¨te â†’ tu rebascules en 1 seconde

#### 3. Canary Release
```
v1.0 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 95% du trafic
v1.1 â–ˆâ–ˆ                        5% du trafic
```
- Tu envoies 5% des utilisateurs sur la nouvelle version
- Tu monitores les mÃ©triques (erreurs, latence)
- Si tout va bien â†’ 25% â†’ 50% â†’ 100%
- Si Ã§a pÃ¨te â†’ tout le monde revient sur v1.0

### Feature Flags
Une alternative au rollback : le code est dÃ©ployÃ© mais **dÃ©sactivÃ©**.

```typescript
if (featureFlags.isEnabled('new_scoring_v4')) {
  return calculateScoreV4(patient);
} else {
  return calculateScoreV3(patient); // Version stable
}
```

Tu actives/dÃ©sactives la fonctionnalitÃ© via une interface (LaunchDarkly, Unleash), **sans redÃ©ployer**. Si le nouveau scoring bugue â†’ tu l'Ã©teins en 2 secondes.

---

## 10.7 â€” SLA / SLO / SLI

### Le concept
Des **engagements mesurables** sur la qualitÃ© du service.

| Terme | Signification | Exemple |
|-------|--------------|---------|
| **SLI** (Indicator) | Ce qu'on mesure | "Le temps de rÃ©ponse de l'API" |
| **SLO** (Objective) | L'objectif qu'on se fixe | "Le P99 doit Ãªtre < 500ms" |
| **SLA** (Agreement) | L'engagement contractuel | "99.9% de disponibilitÃ© ou remboursement" |

**Analogie** : SLI = le compteur de vitesse. SLO = la limite Ã  130. SLA = l'amende si tu dÃ©passes.

**99.9% de disponibilitÃ©** (le fameux "trois neuf") = au maximum **8h45 de downtime par an**. Ã‡a paraÃ®t beaucoup, mais certains services visent 99.99% (52 min/an).

### Error Budget
Un concept malin : si ton SLO est 99.9%, tu as un **budget d'erreur de 0.1%**. Tant que tu restes dans le budget, tu peux prendre des risques (dÃ©ployer souvent, expÃ©rimenter). Si tu le consommes â†’ tu arrÃªtes de deploy et tu stabilises.

---

## 10.8 â€” Incident Management

### Le concept
Quand l'app tombe en prod (et Ã§a arrivera), **que fait-on ?**

### Le flow d'incident

```
1. DETECTION â†’ Monitoring alerte automatiquement
2. TRIAGE    â†’ Quel est l'impact ? (P1 = critique, P4 = mineur)
3. RÃ‰PONSE   â†’ L'on-call prend en charge, communique
4. RÃ‰SOLUTION â†’ Fix, rollback, ou workaround
5. POST-MORTEM â†’ Analyse Ã  froid, actions prÃ©ventives
```

### Post-Mortem (Blameless)

AprÃ¨s chaque incident majeur, on rÃ©dige un **post-mortem** :
- **Quoi** : Ce qui s'est passÃ©
- **Timeline** : Minute par minute
- **Impact** : Combien d'utilisateurs, combien de temps
- **Root Cause** : Pourquoi c'est arrivÃ© (vraiment)
- **Actions** : Ce qu'on met en place pour que Ã§a n'arrive plus

**Blameless** = on ne cherche pas QUI a merdÃ©, mais POURQUOI le systÃ¨me a permis que Ã§a arrive. C'est une culture, pas juste un document.

### Runbooks

Des **guides opÃ©rationnels** prÃ©rÃ©digÃ©s pour les incidents courants :
```markdown
# Runbook : Base de donnÃ©es inaccessible

## SymptÃ´mes
- Erreurs 500 sur toutes les requÃªtes
- Logs : "connection refused" sur PostgreSQL

## Diagnostic
1. VÃ©rifier le status Supabase : https://status.supabase.com
2. VÃ©rifier les connexions actives dans le dashboard
3. Tester la connexion depuis une Edge Function

## RÃ©solution
1. Si Supabase est down â†’ attendre + communiquer aux utilisateurs
2. Si connection pool saturÃ© â†’ redÃ©marrer le service
3. Si migration cassÃ©e â†’ rollback la derniÃ¨re migration
```

---

> ğŸ’¡ **Ce que le CTO va retenir** : Tu sais ce qui manque, tu sais ce qu'il faut faire, et tu as un plan. C'est exactement la maturitÃ© qu'il cherche â€” pas un code parfait, mais une **conscience professionnelle** de ce que "production" signifie.
